{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZgNh-glCZun"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"bhaveshmittal/melanoma-cancer-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "print(os.listdir(\"/kaggle/input/melanoma-cancer-dataset\"))\n",
        "print(os.listdir(\"/kaggle/input/melanoma-cancer-dataset/train\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmyMQ11Aufht"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device in use:\", device)\n",
        "\n",
        "# Parameters\n",
        "imgSize = 224\n",
        "batchSize = 32\n",
        "epochs = 20\n",
        "patience = 5\n",
        "minDelta = 0.01\n",
        "\n",
        "# Transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomHorizontalFlip(0.3),\n",
        "    transforms.RandomVerticalFlip(0.3),\n",
        "    transforms.Resize((imgSize, imgSize)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((imgSize, imgSize)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Paths dari KaggleHub\n",
        "train_path = \"/kaggle/input/melanoma-cancer-dataset/train\"\n",
        "val_path   = \"/kaggle/input/melanoma-cancer-dataset/test\"\n",
        "\n",
        "# Load dataset\n",
        "train_dataset = datasets.ImageFolder(train_path, transform=train_transform)\n",
        "val_dataset   = datasets.ImageFolder(val_path, transform=val_transform)\n",
        "\n",
        "trainLoader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True, num_workers=2)\n",
        "valLoader   = DataLoader(val_dataset, batch_size=batchSize, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Classes:\", train_dataset.classes)\n",
        "\n",
        "# === ResNet50 ===\n",
        "model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 1)   # Binary classification\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss & Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, threshold=minDelta, factor=0.1, patience=3, min_lr=1e-5)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Tracking\n",
        "trainLosses, valLosses, valAccs = [], [], []\n",
        "bestLoss = float('inf')\n",
        "currentPatience = 0\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    runningLoss = 0.0\n",
        "\n",
        "    for inputs, labels in trainLoader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1).float()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        runningLoss += loss.item()\n",
        "\n",
        "    trainLoss = runningLoss / len(trainLoader)\n",
        "    trainLosses.append(trainLoss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    valLoss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valLoader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1).float()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            valLoss += loss.item()\n",
        "\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avgValLoss = valLoss / len(valLoader)\n",
        "    accuracy = correct / total * 100\n",
        "    valLosses.append(avgValLoss)\n",
        "    valAccs.append(accuracy)\n",
        "\n",
        "    print(f\"[{epoch+1}/{epochs}] Train Loss: {trainLoss:.3f} | Val Loss: {avgValLoss:.3f} | Val Acc: {accuracy:.2f}%\")\n",
        "\n",
        "    # Early stopping\n",
        "    if avgValLoss < bestLoss - minDelta:\n",
        "        bestLoss = avgValLoss\n",
        "        currentPatience = 0\n",
        "    else:\n",
        "        currentPatience += 1\n",
        "        if currentPatience >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    scheduler.step(avgValLoss)\n",
        "\n",
        "# Plot loss & accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(trainLosses, label=\"Train Loss\")\n",
        "plt.plot(valLosses, label=\"Val Loss\")\n",
        "plt.legend(); plt.title(\"Loss Curve\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(valAccs, label=\"Val Accuracy\")\n",
        "plt.legend(); plt.title(\"Validation Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix\n",
        "model.eval()\n",
        "allLabels, allPreds = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in valLoader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.unsqueeze(1).float().to(device)\n",
        "        outputs = model(inputs)\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "\n",
        "        allLabels.extend(labels.cpu().numpy())\n",
        "        allPreds.extend(preds.cpu().numpy())\n",
        "\n",
        "matrix = confusion_matrix(allLabels, allPreds)\n",
        "sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=train_dataset.classes,\n",
        "            yticklabels=train_dataset.classes)\n",
        "plt.title(\"Confusion Matrix (Validation)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQnsBzvdELc6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "allLabels_flat = [int(x[0]) for x in allLabels]\n",
        "allPreds_flat = [int(x[0]) for x in allPreds]\n",
        "\n",
        "class_names = train_dataset.classes  # ['Benign', 'Malignant']\n",
        "\n",
        "# Classification report\n",
        "report_dict = classification_report(\n",
        "    allLabels_flat,\n",
        "    allPreds_flat,\n",
        "    target_names=class_names,\n",
        "    output_dict=True\n",
        ")\n",
        "\n",
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "report_df[['precision', 'recall', 'f1-score']] = report_df[['precision', 'recall', 'f1-score']] * 100\n",
        "report_df = report_df.round(2)\n",
        "\n",
        "print(\"=== Classification Report (%) ===\")\n",
        "print(report_df)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
